{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgMeyL7pkgdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEuJPJ4yrGCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwL5Modqp6Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "\n",
        "root_dir_train = '/content/drive/My Drive/DataSet Desafio BB/data/train'\n",
        "root_dir_test = '/content/drive/My Drive/DataSet Desafio BB/data/test'\n",
        "\n",
        "\n",
        "def getimagedataandlabels(root_dir, image_w, image_h):\n",
        "\n",
        "    X_data=[]\n",
        "    Y_data=[]\n",
        "    classes_from_directories = []  # to determine the classes from the root folder structure automatically\n",
        "\n",
        "    for directory, subdirectories, files in os.walk(root_dir):\n",
        "        for subdirectory in subdirectories:\n",
        "            classes_from_directories.append(subdirectory)\n",
        "        for file in files:\n",
        "            if file != '.DS_Store':  # fix for MAC...\n",
        "                imagepath = os.path.join(directory, file)\n",
        "                current_image_class_splitt = imagepath.split('/')\n",
        "                current_image_class = current_image_class_splitt[len(current_image_class_splitt) - 2]\n",
        "                img = cv2.imread (imagepath)\n",
        "                X_data.append(np.asarray(img, dtype=\"int32\"))\n",
        "                Y_data.append(current_image_class)\n",
        "               \n",
        "\n",
        "    return np.array(X_data), np.array(Y_data)\n",
        "\n",
        "#Loading the training images\n",
        "x_train, y_train = getimagedataandlabels(root_dir_train, 256, 256)\n",
        "print(\"Training images and labels loaded\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "#Loading the te\n",
        "x_test, y_test = getimagedataandlabels(root_dir_test, 256, 256)\n",
        "print(\"Test images and labels loaded\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "#Brining the labels into the correct format for categorical crossentropy\n",
        "encoder = LabelBinarizer()\n",
        "Y_train = encoder.fit_transform(y_train)\n",
        "Y_test = encoder.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfj5KfgauDVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ2X3Ham0Pl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.05))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.05))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(rate=0.10))\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(rate=0.10))\n",
        "model.add(tf.keras.layers.Dense(units=5, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "list_callbacks = [\n",
        "    ModelCheckpoint(filepath='best_model.hdf5', monitor='val_accuracy', verbose=1, mode='max', save_best_only=True),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=1000, verbose=1, mode='max', restore_best_weights=True)\n",
        "]\n",
        "\n",
        "model.fit(x_train / 255, Y_train, \n",
        "          batch_size=8, \n",
        "          epochs=1000, \n",
        "          validation_data=(x_test / 255,Y_test),\n",
        "          callbacks=list_callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}